{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-09T04:23:43.064783Z",
     "iopub.status.busy": "2026-01-09T04:23:43.064499Z",
     "iopub.status.idle": "2026-01-09T04:23:48.544485Z",
     "shell.execute_reply": "2026-01-09T04:23:48.543590Z",
     "shell.execute_reply.started": "2026-01-09T04:23:43.064756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!export PATH=\"${HOME}/.local/bin:${PATH}\" && uv pip uninstall --system --quiet jax tensorflow tensorflow-tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:23:48.545309Z",
     "iopub.status.busy": "2026-01-09T04:23:48.545150Z",
     "iopub.status.idle": "2026-01-09T04:24:18.903290Z",
     "shell.execute_reply": "2026-01-09T04:24:18.902409Z",
     "shell.execute_reply.started": "2026-01-09T04:23:48.545292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!export PATH=\"${HOME}/.local/bin:${PATH}\" && uv pip install --system --quiet tensorflow==\"2.18.0\"\n",
    "!export PATH=\"${HOME}/.local/bin:${PATH}\" && uv pip install --system --quiet imagehash\n",
    "!export PATH=\"${HOME}/.local/bin:${PATH}\" && uv pip install --system --quiet tensorflow-tpu==\"2.18.0\" --find-links https://storage.googleapis.com/libtpu-tf-releases/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:24:18.904283Z",
     "iopub.status.busy": "2026-01-09T04:24:18.904110Z",
     "iopub.status.idle": "2026-01-09T04:25:00.987588Z",
     "shell.execute_reply": "2026-01-09T04:25:00.986447Z",
     "shell.execute_reply.started": "2026-01-09T04:24:18.904267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import imagehash\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import concurrent\n",
    "import albumentations as A \n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "# ==========================================\n",
    "# 0. DỌN DẸP CACHE\n",
    "# ==========================================\n",
    "for f in glob.glob('/kaggle/working/*.lockfile') + glob.glob('/kaggle/working/*cache*'):\n",
    "    try:\n",
    "        if os.path.isdir(f): shutil.rmtree(f)\n",
    "        else: os.remove(f)\n",
    "    except: pass\n",
    "# ==========================================\n",
    "# 1. CẤU HÌNH TPU/GPU\n",
    "# ==========================================\n",
    "def get_strategy():\n",
    "    try:\n",
    "        if 'TPU_NAME' not in os.environ and 'TPU_ACCELERATOR_TYPE' not in os.environ:\n",
    "             raise RuntimeError(\"No TPU environment variables found.\")\n",
    "        \n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU\")\n",
    "        return strategy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"TPU init failed or not detected: {type(e).__name__}. Falling back to GPU/CPU...\")\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "            if len(gpus) > 1:\n",
    "                strategy = tf.distribute.MirroredStrategy()\n",
    "                print(f\"Running on {len(gpus)} GPUs (MirroredStrategy)\")\n",
    "            else:\n",
    "                strategy = tf.distribute.OneDeviceStrategy(device=\"/GPU:0\")\n",
    "                print(\"Running on single GPU\")\n",
    "\n",
    "            return strategy\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(\"GPU init failed:\", e)\n",
    "    print(\"Running on CPU\")\n",
    "    return tf.distribute.get_strategy()\n",
    "\n",
    "strategy = get_strategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:25:00.988523Z",
     "iopub.status.busy": "2026-01-09T04:25:00.988326Z",
     "iopub.status.idle": "2026-01-09T04:30:51.420332Z",
     "shell.execute_reply": "2026-01-09T04:30:51.419085Z",
     "shell.execute_reply.started": "2026-01-09T04:25:00.988504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =================================\n",
    "# 2. DATA CLEANING & PRE-PROCESSING\n",
    "# =================================\n",
    "USNS_DATA_DIR = '/kaggle/input/ultrasound-nerve-segmentation/train'\n",
    "BUSI_DATA_DIR = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "CAMUS_DATA_DIR = '/kaggle/input/camus-echocardiography-image-dataset'\n",
    "DDTI_DATA_DIR = '/kaggle/input/ddti-thyroid-ultrasound-images'\n",
    "THYROID_RAW_DIR = '/kaggle/input/ultrasounddataset-andmat/Thyroid Dataset'\n",
    "\n",
    "WORKING_DIR = '/kaggle/working/data_png'\n",
    "GEN_MASKS_DIR = '/kaggle/working/generated_masks'\n",
    "PROCESSED_USNS_DIR = '/kaggle/working/processed_usns'\n",
    "PROCESSED_THYROID_DIR = '/kaggle/working/processed_thyroid'\n",
    "PROCESSED_OTHERS_DIR = '/kaggle/working/processed_others'\n",
    "\n",
    "TARGET_HEIGHT = 512\n",
    "TARGET_WIDTH = 512\n",
    "\n",
    "for d in [WORKING_DIR, GEN_MASKS_DIR, PROCESSED_USNS_DIR, PROCESSED_THYROID_DIR, PROCESSED_OTHERS_DIR]:\n",
    "    if not os.path.exists(d): os.makedirs(d)\n",
    "\n",
    "def get_patient_id(file_path, source):\n",
    "    \"\"\"\n",
    "    Trích xuất Patient ID từ đường dẫn file dựa trên quy tắc từng dataset.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    if source == 'USNS':\n",
    "        return f\"usns_{filename.split('_')[0]}\"\n",
    "    \n",
    "    elif source == 'DDTI':\n",
    "        try:\n",
    "            pid = filename.split('_')[1].split('.')[0]\n",
    "            return f\"ddti_{pid}\"\n",
    "        except:\n",
    "            return f\"ddti_{filename}\"\n",
    "            \n",
    "    elif source == 'CAMUS':\n",
    "        parent_dir = os.path.basename(os.path.dirname(file_path))\n",
    "        return f\"camus_{parent_dir}\"\n",
    "        \n",
    "    elif source == 'BUSI':\n",
    "        return f\"busi_{filename.replace('.png', '')}\"\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "def create_meta_dataframe(img_paths, mask_paths):\n",
    "    data = []\n",
    "    \n",
    "    print(\"Đang tạo bảng Meta-data...\")\n",
    "    for img, msk in zip(img_paths, mask_paths):\n",
    "        if 'BUSI' in img: source = 'BUSI'\n",
    "        elif 'DDTI' in img: source = 'DDTI'\n",
    "        elif 'CAMUS' in img: source = 'CAMUS'\n",
    "        else: source = 'USNS'\n",
    "        \n",
    "        pid = get_patient_id(img, source)\n",
    "        \n",
    "        data.append({\n",
    "            'image_path': img,\n",
    "            'mask_path': msk,\n",
    "            'source': source,\n",
    "            'patient_id': pid,\n",
    "            'hash': None,\n",
    "            'has_nerve': -1\n",
    "        })\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def process_metadata(df):\n",
    "    \"\"\"\n",
    "    Tính pHash để xóa trùng và Check mask để dán nhãn phân lớp.\n",
    "    \"\"\"\n",
    "    hashes = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Hashing & Labeling...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            img = Image.open(row['image_path'])\n",
    "            h = imagehash.phash(img)\n",
    "            hashes.append(str(h))\n",
    "        except:\n",
    "            hashes.append(\"error\")\n",
    "        try:\n",
    "            msk = cv2.imread(row['mask_path'], 0)\n",
    "            if msk is None:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1 if np.max(msk) > 0 else 0)\n",
    "        except:\n",
    "            labels.append(0)\n",
    "    \n",
    "    df['hash'] = hashes\n",
    "    df['has_nerve'] = labels\n",
    "    return df\n",
    "\n",
    "def remove_duplicates(df, threshold=5):\n",
    "    print(f\"Before: {len(df)} samples\")\n",
    "\n",
    "    df_clean = df.drop_duplicates(subset=['hash'], keep='first')\n",
    "\n",
    "    df_clean = df_clean[df_clean['hash'] != \"error\"]\n",
    "    \n",
    "    print(f\"After: {len(df_clean)} samples\")\n",
    "    return df_clean\n",
    "\n",
    "def split_data(df, n_splits=5):\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "\n",
    "    df['fold'] = -1\n",
    "\n",
    "    X = df['image_path']\n",
    "    y = df['has_nerve']\n",
    "    groups = df['patient_id']\n",
    "    \n",
    "    print(\"Fold Spliting...\")\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(sgkf.split(X, y, groups)):\n",
    "        df.loc[val_idx, 'fold'] = fold_idx\n",
    "        train_y = y.iloc[train_idx]\n",
    "        val_y = y.iloc[val_idx]\n",
    "        print(f\"Fold {fold_idx}:\")\n",
    "        print(f\"  Train: {len(train_idx)} (Pos: {train_y.sum()}, Neg: {len(train_y)-train_y.sum()})\")\n",
    "        print(f\"  Val  : {len(val_idx)} (Pos: {val_y.sum()}, Neg: {len(val_y)-val_y.sum()})\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "offline_aug = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(alpha=70, sigma=120 * 0.05, p=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=1.0),\n",
    "        A.OpticalDistortion(distort_limit=0.3, p=1.0),\n",
    "        A.Affine(scale=(0.9, 1.1), translate_percent=(-0.05, 0.05), rotate=(-10, 10), p=1.0),\n",
    "    ], p=0.8),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=0.5, elementwise=True),                  \n",
    "    ], p=0.4)\n",
    "], p=1.0)\n",
    "\n",
    "def generate_ddti_masks(ddti_root_dir, output_mask_dir):\n",
    "    if not os.path.exists(output_mask_dir):\n",
    "        os.makedirs(output_mask_dir)\n",
    "    xml_files = glob.glob(os.path.join(ddti_root_dir, \"*.xml\"))\n",
    "    print(f\"{len(xml_files)} file XML. Preprocessing...\")\n",
    "\n",
    "    success_count = 0\n",
    "\n",
    "    for xml_path in tqdm(xml_files):\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            number_tag = root.find('number')\n",
    "            if number_tag is None:\n",
    "                continue\n",
    "\n",
    "            patient_id = number_tag.text\n",
    "            image_annotations = {}\n",
    "\n",
    "            for mark in root.findall('mark'):\n",
    "                img_idx = mark.find('image').text\n",
    "                svg_tag = mark.find('svg')\n",
    "\n",
    "                if img_idx and svg_tag is not None and svg_tag.text:\n",
    "                    try:\n",
    "                        shapes = json.loads(svg_tag.text)\n",
    "                        if img_idx not in image_annotations:\n",
    "                            image_annotations[img_idx] = []\n",
    "\n",
    "                        for shape in shapes:\n",
    "                            if \"points\" in shape:\n",
    "                                pts = np.array([[p['x'], p['y']] for p in shape[\"points\"]], dtype=np.int32)\n",
    "                                pts = pts.reshape((-1, 1, 2))\n",
    "                                image_annotations[img_idx].append(pts)\n",
    "                    except: pass\n",
    "            potential_images = glob.glob(os.path.join(ddti_root_dir, f\"{patient_id}_*.*\"))\n",
    "\n",
    "            for img_path in potential_images:\n",
    "                filename = os.path.basename(img_path)\n",
    "                if filename.endswith('.xml'): continue\n",
    "                name_no_ext = os.path.splitext(filename)[0]\n",
    "                parts = name_no_ext.split('_')\n",
    "                if len(parts) < 2: continue\n",
    "\n",
    "                current_img_idx = parts[-1]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None: continue\n",
    "                h, w = img.shape[:2]\n",
    "\n",
    "                mask = np.zeros((h, w), dtype=np.uint8)\n",
    "                if current_img_idx in image_annotations:\n",
    "                    for pts in image_annotations[current_img_idx]:\n",
    "                        cv2.fillPoly(mask, [pts], color=255)\n",
    "                mask_filename = filename.rsplit('.', 1)[0] + \"_mask.png\"\n",
    "                save_path = os.path.join(output_mask_dir, mask_filename)\n",
    "                cv2.imwrite(save_path, mask)\n",
    "                success_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi xử lý {xml_path}: {e}\")\n",
    "\n",
    "def offline_aug_fn(image, mask):\n",
    "    return offline_aug(image=image, mask=mask)\n",
    "\n",
    "def get_patient_id(file_path, source):\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    if source == 'USNS':\n",
    "        return f\"usns_{filename.split('_')[0]}\" \n",
    "        \n",
    "    elif source == 'DDTI':\n",
    "        try: return f\"ddti_{filename.split('_')[0]}\"\n",
    "        except: return f\"ddti_{filename}\"\n",
    "        \n",
    "    elif source == 'CAMUS':\n",
    "        return f\"camus_{filename.split('_')[0]}\"\n",
    "        \n",
    "    elif source == 'BUSI':\n",
    "        return f\"busi_{filename.split(' ')[0]}\" \n",
    "\n",
    "    elif source == 'THYROID_EXT':\n",
    "        return f\"thyroid_{filename.replace('.png', '')}\"\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "def resize_and_pad_offline(image, target_h, target_w, interpolation=cv2.INTER_LINEAR):\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    scale = min(target_h / h, target_w / w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "\n",
    "    resized = cv2.resize(image, (new_w, new_h), interpolation=interpolation)\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)\n",
    "    else:\n",
    "        canvas = np.zeros((target_h, target_w), dtype=np.uint8)\n",
    "\n",
    "    pad_top = (target_h - new_h) // 2\n",
    "    pad_left = (target_w - new_w) // 2\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        canvas[pad_top:pad_top+new_h, pad_left:pad_left+new_w, :] = resized\n",
    "    else:\n",
    "        canvas[pad_top:pad_top+new_h, pad_left:pad_left+new_w] = resized\n",
    "        \n",
    "    return canvas\n",
    "\n",
    "def process_single_augment_task(args):\n",
    "    img_path, mask_path, output_dir, num_aug, prefix = args\n",
    "    \n",
    "    try:\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        if image is None or mask is None: return\n",
    "\n",
    "        image = resize_and_pad_offline(image, TARGET_HEIGHT, TARGET_WIDTH, cv2.INTER_CUBIC)\n",
    "        mask = resize_and_pad_offline(mask, TARGET_HEIGHT, TARGET_WIDTH, cv2.INTER_NEAREST)\n",
    "\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        if prefix: base_name = f\"{prefix}_{base_name}\"\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_dir, f\"{base_name}.png\"), image)\n",
    "        cv2.imwrite(os.path.join(output_dir, f\"{base_name}_mask.png\"), mask)\n",
    "\n",
    "        if num_aug > 0 and np.sum(mask) > 0:\n",
    "            for i in range(num_aug):\n",
    "                aug = offline_aug_fn(image, mask)\n",
    "                cv2.imwrite(os.path.join(output_dir, f\"{base_name}_aug_{i}.png\"), aug['image'])\n",
    "                cv2.imwrite(os.path.join(output_dir, f\"{base_name}_aug_{i}_mask.png\"), aug['mask'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "def prep_usns(raw_dir, out_dir):\n",
    "    mask_files = glob.glob(os.path.join(raw_dir, \"*_mask.tif\"))\n",
    "    mask_files.sort() \n",
    "    \n",
    "    tasks = []\n",
    "    for m_path in mask_files:\n",
    "        img_path = m_path.replace('_mask.tif', '.tif')\n",
    "        if os.path.exists(img_path):\n",
    "            tasks.append((img_path, m_path, out_dir, 0, \"\"))\n",
    "\n",
    "    print(f\"Processing USNS: {len(mask_files)} tasks...\")\n",
    "    return tasks\n",
    "\n",
    "def prep_thyroid_merged(root_dir, ddti_img_dir, ddti_mask_dir, out_dir):\n",
    "    tasks = []\n",
    "    subsets = [\n",
    "        (os.path.join(root_dir, \"tg3k/thyroid-image\"), os.path.join(root_dir, \"tg3k/thyroid-mask\"), \"tg3k\"),\n",
    "        (os.path.join(root_dir, \"tn3k/trainval-image\"), os.path.join(root_dir, \"tn3k/trainval-mask\"), \"tn3k_tr\"),\n",
    "        (os.path.join(root_dir, \"tn3k/test-image\"), os.path.join(root_dir, \"tn3k/test-mask\"), \"tn3k_ts\")\n",
    "    ]\n",
    "    \n",
    "    for img_d, msk_d, prefix in subsets:\n",
    "        if not os.path.exists(img_d): continue\n",
    "        imgs = glob.glob(os.path.join(img_d, \"*\"))\n",
    "        for i_path in imgs:\n",
    "            fname = os.path.basename(i_path).split('.')[0]\n",
    "            m_path = None\n",
    "            for ext in ['.png', '.jpg', '_mask.png', '_mask.jpg']:\n",
    "                potential = os.path.join(msk_d, fname + ext)\n",
    "                if os.path.exists(potential):\n",
    "                    m_path = potential\n",
    "                    break\n",
    "            \n",
    "            if m_path:\n",
    "                tasks.append((i_path, m_path, out_dir, 0, prefix))\n",
    "\n",
    "    ddti_imgs = glob.glob(os.path.join(ddti_img_dir, \"*.png\"))\n",
    "    for i_path in ddti_imgs:\n",
    "        fname = os.path.basename(i_path).split('.')[0]\n",
    "        m_path = os.path.join(ddti_mask_dir, fname + \"_mask.png\")\n",
    "        if os.path.exists(m_path):\n",
    "            tasks.append((i_path, m_path, out_dir, 2, \"ddti\"))\n",
    "\n",
    "    print(f\"Processing Thyroid Merged: {len(tasks)} tasks...\")\n",
    "    return tasks\n",
    "\n",
    "def prep_others(busi_dir, camus_dir, out_dir):\n",
    "    tasks = []\n",
    "    NUM_AUG = 4 \n",
    "\n",
    "    for sub in ['benign', 'malignant']:\n",
    "        d = os.path.join(busi_dir, sub)\n",
    "        if os.path.exists(d):\n",
    "            imgs = [f for f in os.listdir(d) if 'mask' not in f and f.endswith('.png')]\n",
    "            for f in imgs:\n",
    "                i_path = os.path.join(d, f)\n",
    "                m_path = os.path.join(d, f.replace('.png', '_mask.png'))\n",
    "                if os.path.exists(m_path):\n",
    "                    tasks.append((i_path, m_path, out_dir, NUM_AUG, \"busi\"))\n",
    "\n",
    "    camus_f = os.path.join(camus_dir, 'frames')\n",
    "    camus_m = os.path.join(camus_dir, 'masks')\n",
    "    if os.path.exists(camus_f):\n",
    "        frames = glob.glob(os.path.join(camus_f, \"*.png\"))\n",
    "        for i_path in frames:\n",
    "            fname = os.path.basename(i_path)\n",
    "            m_path = os.path.join(camus_m, fname.replace('frame_', 'mask_'))\n",
    "            if os.path.exists(m_path):\n",
    "                tasks.append((i_path, m_path, out_dir, NUM_AUG, \"camus\"))\n",
    "                \n",
    "    print(f\"Processing Others (BUSI/CAMUS): {len(tasks)} tasks...\")\n",
    "    return tasks\n",
    "\n",
    "def main_processing():\n",
    "    generate_ddti_masks(DDTI_DATA_DIR, GEN_MASKS_DIR)\n",
    "    all_tasks = []\n",
    "\n",
    "    all_tasks.extend(prep_usns(USNS_DATA_DIR, PROCESSED_USNS_DIR))\n",
    "    all_tasks.extend(prep_thyroid_merged(THYROID_RAW_DIR, DDTI_DATA_DIR, GEN_MASKS_DIR, PROCESSED_THYROID_DIR))\n",
    "    all_tasks.extend(prep_others(BUSI_DATA_DIR, CAMUS_DATA_DIR, PROCESSED_OTHERS_DIR))\n",
    "    \n",
    "    print(f\"Total task: {len(all_tasks)}\")\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        list(tqdm(executor.map(process_single_augment_task, all_tasks), total=len(all_tasks)))\n",
    "\n",
    "    data_entries = []\n",
    "    \n",
    "    for folder, src_name in [(PROCESSED_USNS_DIR, 'USNS'), \n",
    "                             (PROCESSED_THYROID_DIR, 'THYROID_EXT'), \n",
    "                             (PROCESSED_OTHERS_DIR, 'OTHERS')]:\n",
    "        \n",
    "        mask_files = glob.glob(os.path.join(folder, \"*_mask.png\"))\n",
    "        for m_path in mask_files:\n",
    "            i_path = m_path.replace('_mask.png', '.png')\n",
    "            if not os.path.exists(i_path): continue\n",
    "\n",
    "            real_source = src_name\n",
    "            fname = os.path.basename(i_path)\n",
    "            if 'busi' in fname: real_source = 'BUSI'\n",
    "            elif 'camus' in fname: real_source = 'CAMUS'\n",
    "            elif 'tn3k' in fname or 'tg3k' in fname: real_source = 'THYROID_EXT'\n",
    "            \n",
    "            pid = get_patient_id(i_path, real_source)\n",
    "            is_aug = '_aug_' in fname\n",
    "            \n",
    "            data_entries.append({\n",
    "                'image_path': i_path,\n",
    "                'mask_path': m_path,\n",
    "                'source': real_source,\n",
    "                'patient_id': pid,\n",
    "                'is_augmented': is_aug\n",
    "            })\n",
    "            \n",
    "    df = pd.DataFrame(data_entries)\n",
    "\n",
    "    df = process_metadata(df)\n",
    "    df = remove_duplicates(df)\n",
    "\n",
    "    df = split_data(df, n_splits=5)\n",
    "    \n",
    "    df.to_csv('unified_medical_data_5folds.csv', index=False)\n",
    "\n",
    "main_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:30:51.421220Z",
     "iopub.status.busy": "2026-01-09T04:30:51.421054Z",
     "iopub.status.idle": "2026-01-09T04:31:21.955877Z",
     "shell.execute_reply": "2026-01-09T04:31:21.954574Z",
     "shell.execute_reply.started": "2026-01-09T04:30:51.421203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3. NATIVE TF DATA PIPELINE\n",
    "# ==========================\n",
    "BATCH_SIZE_PER_REPLICA = 8\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4 * (BATCH_SIZE_PER_REPLICA / 8) * strategy.num_replicas_in_sync\n",
    "df = pd.read_csv('/kaggle/working/unified_medical_data_5folds.csv')\n",
    "\n",
    "fold_idx = 0\n",
    "df_train = df[df['fold'] != fold_idx]\n",
    "df_val = df[(df['fold'] == fold_idx) & (df['is_augmented'] == False)]\n",
    "\n",
    "train_imgs = df_train['image_path'].tolist()\n",
    "train_masks = df_train['mask_path'].tolist()\n",
    "\n",
    "val_imgs = df_val['image_path'].tolist()\n",
    "val_masks = df_val['mask_path'].tolist()\n",
    "\n",
    "def load_raw_data(img_path, mask_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    \n",
    "    if img.dtype != tf.uint8:\n",
    "        img = tf.cast(tf.clip_by_value(img, 0, 255), tf.uint8)\n",
    "\n",
    "    mask = tf.cast(mask > 0, tf.uint8)\n",
    "\n",
    "    return img.numpy(), mask.numpy()\n",
    "\n",
    "def load_dataset_into_ram(img_paths, mask_paths):\n",
    "    X_data = np.zeros((len(img_paths), TARGET_HEIGHT, TARGET_WIDTH, 3), dtype=np.uint8)\n",
    "    y_data = np.zeros((len(img_paths), TARGET_HEIGHT, TARGET_WIDTH, 1), dtype=np.uint8)\n",
    "    def load_single(idx, p, m):\n",
    "        try:\n",
    "            img_raw, mask_raw = load_raw_data(p, m)\n",
    "            if len(mask_raw.shape) == 2:\n",
    "                mask_raw = np.expand_dims(mask_raw, axis=-1)\n",
    "            if len(img_raw.shape) == 2:\n",
    "                 img_raw = np.stack((img_raw,)*3, axis=-1)\n",
    "\n",
    "            return idx, img_raw, mask_raw\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi ảnh {p}: {e}\")\n",
    "            return None\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        futures = [executor.submit(load_single, i, p, m)\n",
    "                   for i, (p, m) in enumerate(zip(img_paths, mask_paths))]\n",
    "\n",
    "        for f in tqdm(concurrent.futures.as_completed(futures), total=len(img_paths)):\n",
    "            result = f.result()\n",
    "            if result is not None:\n",
    "                idx, img, msk = result\n",
    "                X_data[idx] = img\n",
    "                y_data[idx] = msk\n",
    "\n",
    "    print(f\"RAM: {X_data.nbytes / 1e9:.2f} GB\")\n",
    "    return X_data, y_data\n",
    "\n",
    "X_train, y_train = load_dataset_into_ram(train_imgs, train_masks)\n",
    "X_val, y_val = load_dataset_into_ram(val_imgs, val_masks)\n",
    "\n",
    "def get_unified_dataset(img, mask, batch_size=BATCH_SIZE, training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img, mask))\n",
    "    dataset = dataset.cache()\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size=len(img))\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        dataset = dataset.batch(max(1, batch_size // 2), drop_remainder=True)\n",
    "\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA \n",
    "    dataset = dataset.with_options(options)\n",
    "    return dataset\n",
    "\n",
    "train_ds = get_unified_dataset(X_train, y_train, training=True)\n",
    "val_ds = get_unified_dataset(X_val, y_val, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:31:26.241662Z",
     "iopub.status.busy": "2026-01-09T04:31:26.241458Z",
     "iopub.status.idle": "2026-01-09T04:31:26.468049Z",
     "shell.execute_reply": "2026-01-09T04:31:26.466949Z",
     "shell.execute_reply.started": "2026-01-09T04:31:26.241646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. MODEL ARGA MULTI-TASK VỚI BONDARY LEARNING\n",
    "# ==============================================\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MedicalPreprocessingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_height=512, target_width=512, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "        self.kernel_size = 3\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        if isinstance(inputs, (list, tuple)):\n",
    "            image, mask = inputs\n",
    "        else:\n",
    "            image = inputs\n",
    "            mask = None\n",
    "            \n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        if training and mask is not None:\n",
    "            combined = tf.concat([image, mask], axis=-1)\n",
    "            PAD = 40\n",
    "            combined = tf.image.pad_to_bounding_box(\n",
    "                combined, PAD, PAD,\n",
    "                self.target_height + 2*PAD, self.target_width + 2*PAD\n",
    "            )\n",
    "            \n",
    "            shape_tensor = tf.shape(image)\n",
    "            if len(image.shape) == 4:\n",
    "                crop_size = [shape_tensor[0], self.target_height, self.target_width, 4]\n",
    "            else:\n",
    "                crop_size = [self.target_height, self.target_width, 4]\n",
    "                \n",
    "            combined = tf.image.random_crop(combined, crop_size)\n",
    "            combined = tf.image.random_flip_left_right(combined)\n",
    "            \n",
    "            image = combined[..., :3]\n",
    "            mask = combined[..., 3:]\n",
    "\n",
    "            image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "            image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "            image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask_for_pool = mask\n",
    "            if len(mask.shape) == 3:\n",
    "                mask_for_pool = tf.expand_dims(mask, 0)\n",
    "\n",
    "            dilated = tf.nn.max_pool2d(mask_for_pool, ksize=self.kernel_size, strides=1, padding='SAME')\n",
    "            eroded = -tf.nn.max_pool2d(-mask_for_pool, ksize=self.kernel_size, strides=1, padding='SAME')\n",
    "            edge = dilated - eroded\n",
    "\n",
    "            if len(mask.shape) == 3:\n",
    "                edge = tf.squeeze(edge, axis=0)\n",
    "\n",
    "            if len(mask.shape) == 4:\n",
    "                max_vals = tf.reduce_max(mask, axis=[1, 2, 3]) \n",
    "                has_object = max_vals > 0.0\n",
    "                label = tf.cast(has_object, tf.float32)\n",
    "                label = tf.reshape(label, [-1, 1])\n",
    "            else:\n",
    "                has_object = tf.reduce_max(mask) > 0.0\n",
    "                label = tf.cast(has_object, tf.float32)\n",
    "                label = tf.reshape(label, [1])\n",
    "\n",
    "            return image, {'seg_out': mask, 'edge_out': edge, 'cls_out': label}\n",
    "\n",
    "        return image\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"target_height\": self.target_height,\n",
    "            \"target_width\": self.target_width\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "class InstanceNormalization(layers.Layer):\n",
    "    \"\"\"\n",
    "    Instance Normalization Layer (Custom Implementation)\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon=1e-7, **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[-1]\n",
    "        self.gamma = self.add_weight(name='gamma', \n",
    "                                     shape=(dim,), \n",
    "                                     initializer='ones', \n",
    "                                     trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', \n",
    "                                    shape=(dim,), \n",
    "                                    initializer='zeros', \n",
    "                                    trainable=True)\n",
    "        super(InstanceNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean, variance = tf.nn.moments(inputs, axes=[1, 2], keepdims=True)\n",
    "        return self.gamma * (inputs - mean) * tf.math.rsqrt(variance + self.epsilon) + self.beta\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(InstanceNormalization, self).get_config()\n",
    "        config.update({'epsilon': self.epsilon})\n",
    "        return config\n",
    "\n",
    "@tf.custom_gradient\n",
    "def grad_scaler(x, scale):\n",
    "    def grad(dy):\n",
    "        return dy * tf.cast(scale, dy.dtype), None \n",
    "    return x, grad\n",
    "\n",
    "class GradientScaler(layers.Layer):\n",
    "    \"\"\"\n",
    "    Layer này cho phép tín hiệu đi qua bình thường (Forward),\n",
    "    nhưng làm yếu Gradient đi khi lan truyền ngược (Backward).\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=0.1, **kwargs):\n",
    "        super(GradientScaler, self).__init__(**kwargs)\n",
    "        self.scale = tf.cast(scale, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_scaler(x, self.scale)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GradientScaler, self).get_config()\n",
    "        config.update({'scale': float(self.scale)})\n",
    "        return config\n",
    "\n",
    "class ChannelMean(layers.Layer):\n",
    "    def call(self, x):\n",
    "        return tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "\n",
    "class ChannelMax(layers.Layer):\n",
    "    def call(self, x):\n",
    "        return tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "\n",
    "def CBAM(inputs, ratio=16, name=\"cbam\"):\n",
    "    channel = inputs.shape[-1]\n",
    "\n",
    "    avg_pool = layers.GlobalAveragePooling2D(name=f\"{name}_gap\")(inputs)\n",
    "    max_pool = layers.GlobalMaxPooling2D(name=f\"{name}_gmp\")(inputs)\n",
    "    \n",
    "    mlp = models.Sequential([\n",
    "        layers.Dense(channel // ratio, activation='swish', use_bias=False, name=f\"{name}_mlp_1\"),\n",
    "        layers.Dense(channel, use_bias=False, name=f\"{name}_mlp_2\")\n",
    "    ], name=f\"{name}_mlp\")\n",
    "    \n",
    "    channel_att = layers.Add(name=f\"{name}_channel_add\")([mlp(avg_pool), mlp(max_pool)])\n",
    "    channel_att = layers.Activation('sigmoid', name=f\"{name}_channel_sigmoid\")(channel_att)\n",
    "    channel_att = layers.Reshape((1, 1, channel), name=f\"{name}_channel_reshape\")(channel_att)\n",
    "    \n",
    "    x = layers.Multiply(name=f\"{name}_channel_mult\")([inputs, channel_att])\n",
    "\n",
    "    avg_pool_s = ChannelMean()(x)\n",
    "    max_pool_s = ChannelMax()(x)\n",
    "\n",
    "    concat = layers.Concatenate(axis=-1, name=f\"{name}_spatial_concat\")([avg_pool_s, max_pool_s])\n",
    "    \n",
    "    spatial_att = layers.Conv2D(1, 7, padding='same', activation='sigmoid', use_bias=False, name=f\"{name}_spatial_conv\")(concat)\n",
    "    x = layers.Multiply(name=f\"{name}_spatial_mult\")([x, spatial_att])\n",
    "    return x\n",
    "\n",
    "def RGCM(inputs, filters, groups=8, reduction=2, name=\"rgcm\"):\n",
    "    residual = inputs\n",
    "    mid_filters = filters // reduction\n",
    "    if mid_filters % groups != 0: mid_filters = ((mid_filters // groups) + 1) * groups\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(mid_filters, 1, use_bias=False, name=f\"{name}_conv1\")(inputs)\n",
    "    x = InstanceNormalization(name=f\"{name}_in1\")(x)\n",
    "    x = layers.Activation('swish', name=f\"{name}_relu1\")(x)\n",
    "    \n",
    "    # Block 2\n",
    "    x = layers.Conv2D(mid_filters, 3, padding='same', groups=groups, use_bias=False, name=f\"{name}_conv2\")(x)\n",
    "    x = InstanceNormalization(name=f\"{name}_in2\")(x)\n",
    "    x = layers.Activation('swish', name=f\"{name}_relu2\")(x)\n",
    "    \n",
    "    # Block 3\n",
    "    x = layers.Conv2D(filters, 1, use_bias=False, name=f\"{name}_conv3\")(x)\n",
    "    x = InstanceNormalization(name=f\"{name}_in3\")(x)\n",
    "    \n",
    "    # Skip Connection\n",
    "    if inputs.shape[-1] != filters:\n",
    "        residual = layers.Conv2D(filters, 1, use_bias=False, name=f\"{name}_shortcut_conv\")(inputs)\n",
    "        residual = InstanceNormalization(name=f\"{name}_shortcut_in\")(residual)\n",
    "        \n",
    "    x = layers.Add(name=f\"{name}_add\")([x, residual])\n",
    "    x = layers.Activation('swish', name=f\"{name}_out_relu\")(x)\n",
    "    return x\n",
    "\n",
    "def GABM(xl, xg, filters, name=\"gabm\"):\n",
    "    theta_x = layers.Conv2D(filters, 1, use_bias=False, name=f\"{name}_theta_conv\")(xl)\n",
    "    theta_x = InstanceNormalization(name=f\"{name}_theta_in\")(theta_x)\n",
    "    \n",
    "    phi_g = layers.Conv2D(filters, 1, use_bias=False, name=f\"{name}_phi_conv\")(xg)\n",
    "    phi_g = InstanceNormalization(name=f\"{name}_phi_in\")(phi_g)\n",
    "    \n",
    "    f = layers.Add(name=f\"{name}_add\")([theta_x, phi_g])\n",
    "    f = layers.Activation('swish', name=f\"{name}_relu\")(f)\n",
    "    \n",
    "    psi = layers.Conv2D(1, 1, use_bias=False, name=f\"{name}_psi_conv\")(f)\n",
    "    psi = InstanceNormalization(name=f\"{name}_psi_in\")(psi)\n",
    "    psi = layers.Activation('sigmoid', name=f\"{name}_psi_sigmoid\")(psi)\n",
    "    \n",
    "    return layers.Multiply(name=f\"{name}_out_mult\")([xl, psi])\n",
    "\n",
    "def ASPP(inputs, out_filters=320, name=\"aspp\"):\n",
    "    \n",
    "    def conv_block(x, kernel_size, dilation_rate=1, block_name=\"block\"):\n",
    "        x = layers.SeparableConv2D(out_filters, kernel_size, padding='same', \n",
    "                          dilation_rate=dilation_rate, use_bias=False, name=f\"{name}_{block_name}_conv\")(x)\n",
    "        x = InstanceNormalization(name=f\"{name}_{block_name}_in\")(x)\n",
    "        x = layers.Activation('swish', name=f\"{name}_{block_name}_relu\")(x)\n",
    "        return x\n",
    "\n",
    "    b1 = conv_block(inputs, 1, dilation_rate=1, block_name=\"b1\")\n",
    "    b2 = conv_block(inputs, 3, dilation_rate=6, block_name=\"b2\")\n",
    "    b3 = conv_block(inputs, 3, dilation_rate=12, block_name=\"b3\")\n",
    "    b4 = conv_block(inputs, 3, dilation_rate=18, block_name=\"b4\")\n",
    "    \n",
    "    b5 = layers.GlobalAveragePooling2D(name=f\"{name}_b5_gap\")(inputs)\n",
    "    b5 = layers.Reshape((1, 1, inputs.shape[-1]), name=f\"{name}_b5_reshape\")(b5)\n",
    "    b5 = layers.Conv2D(out_filters, 1, padding='same', use_bias=False, name=f\"{name}_b5_conv\")(b5)\n",
    "    b5 = InstanceNormalization(name=f\"{name}_b5_in\")(b5)\n",
    "    b5 = layers.Activation('swish', name=f\"{name}_b5_relu\")(b5)\n",
    "    b5 = layers.Lambda(\n",
    "        lambda x: tf.cast(\n",
    "            tf.image.resize(\n",
    "                tf.cast(x[0], tf.float32),\n",
    "                tf.shape(x[1])[1:3]\n",
    "            ),\n",
    "            dtype=x[1].dtype\n",
    "        ),\n",
    "        name=f\"{name}_b5_resize_safe\"\n",
    "    )([b5, inputs])\n",
    "    x = layers.Concatenate(name=f\"{name}_concat\")([b1, b2, b3, b4, b5])\n",
    "    x = conv_block(x, 1, block_name=\"proj\")\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_multitask_arga_unet():\n",
    "    inputs = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name=\"input_1\")\n",
    "    \n",
    "    # --- ENCODER  ---\n",
    "    c1 = layers.Conv2D(32, 3, padding='same', name=\"enc_stem_conv\")(inputs)\n",
    "    c1 = InstanceNormalization(name=\"enc_stem_in\")(c1)\n",
    "    c1 = layers.Activation('swish', name=\"enc_stem_relu\")(c1)\n",
    "    \n",
    "    # Stage 1\n",
    "    r1 = RGCM(c1, 32, name=\"enc_stage1_rgcm\")\n",
    "    p1 = layers.MaxPooling2D(2, name=\"enc_stage1_pool\")(r1)\n",
    "    \n",
    "    # Stage 2\n",
    "    r2 = RGCM(p1, 64, name=\"enc_stage2_rgcm\")\n",
    "    p2 = layers.MaxPooling2D(2, name=\"enc_stage2_pool\")(r2)\n",
    "    \n",
    "    # Stage 3\n",
    "    r3 = RGCM(p2, 128, name=\"enc_stage3_rgcm\")\n",
    "    p3 = layers.MaxPooling2D(2, name=\"enc_stage3_pool\")(r3)\n",
    "    \n",
    "    # Stage 4\n",
    "    r4 = RGCM(p3, 256, name=\"enc_stage4_rgcm\")\n",
    "    p4 = layers.MaxPooling2D(2, name=\"enc_stage4_pool\")(r4)\n",
    "    \n",
    "    # --- BOTTLENECK ---\n",
    "    b_pre = RGCM(p4, 512, name=\"bot_rgcm\")\n",
    "    b = ASPP(b_pre, out_filters=320, name=\"bot_aspp\")\n",
    "    \n",
    "    # --- CLASSIFIER HEAD ---\n",
    "    cls_x = GradientScaler(scale=0.1, name=\"head_cls_scaler\")(b)\n",
    "    cls_x = layers.Conv2D(256, 3, padding='same', activation='swish', kernel_initializer='he_normal', name=\"head_cls_conv\")(cls_x)\n",
    "    cls_x = InstanceNormalization(name=\"head_cls_in\")(cls_x)\n",
    "    \n",
    "    g_avg = layers.GlobalAveragePooling2D(name=\"head_cls_gap\")(cls_x)\n",
    "    g_max = layers.GlobalMaxPooling2D(name=\"head_cls_gmp\")(cls_x)\n",
    "    \n",
    "    cls = layers.Concatenate(name=\"head_cls_concat\")([g_avg, g_max])\n",
    "    cls = layers.Dense(256, activation='swish', kernel_initializer='he_normal', name=\"head_cls_dense1\")(cls)\n",
    "    cls = layers.Dropout(0.5, name=\"head_cls_dropout\")(cls)\n",
    "    \n",
    "    cls_out = layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform', name='head_cls_out', dtype='float32')(cls)\n",
    "    \n",
    "    # --- DECODER ---\n",
    "    \n",
    "    # Block 6\n",
    "    u6 = layers.UpSampling2D(2, interpolation='nearest', name=\"dec_stage6_up\")(b)\n",
    "    g6 = GABM(xl=r4, xg=u6, filters=256, name=\"dec_stage6_gabm\")\n",
    "    c6 = layers.Concatenate(name=\"dec_stage6_concat\")([u6, g6])\n",
    "    \n",
    "    c6 = layers.Conv2D(256, 3, padding='same', use_bias=False, name=\"dec_stage6_conv1\")(c6)\n",
    "    c6 = InstanceNormalization(name=\"dec_stage6_in1\")(c6)\n",
    "    c6 = layers.Activation('swish', name=\"dec_stage6_relu1\")(c6)\n",
    "    c6 = RGCM(c6, 256, name=\"dec_stage6_rgcm\")\n",
    "    c6 = CBAM(c6, name=\"dec_stage6_cbam\")\n",
    "    \n",
    "    # Block 7\n",
    "    u7 = layers.UpSampling2D(2, interpolation='nearest', name=\"dec_stage7_up\")(c6)\n",
    "    g7 = GABM(xl=r3, xg=u7, filters=128, name=\"dec_stage7_gabm\")\n",
    "    c7 = layers.Concatenate(name=\"dec_stage7_concat\")([u7, g7])\n",
    "    \n",
    "    c7 = layers.Conv2D(128, 3, padding='same', use_bias=False, name=\"dec_stage7_conv1\")(c7)\n",
    "    c7 = InstanceNormalization(name=\"dec_stage7_in1\")(c7)\n",
    "    c7 = layers.Activation('swish', name=\"dec_stage7_relu1\")(c7)\n",
    "    c7 = RGCM(c7, 128, name=\"dec_stage7_rgcm\")\n",
    "    c7 = CBAM(c7, name=\"dec_stage7_cbam\")\n",
    "    \n",
    "    # Block 8\n",
    "    u8 = layers.UpSampling2D(2, interpolation='nearest', name=\"dec_stage8_up\")(c7)\n",
    "    g8 = GABM(xl=r2, xg=u8, filters=64, name=\"dec_stage8_gabm\")\n",
    "    c8 = layers.Concatenate(name=\"dec_stage8_concat\")([u8, g8])\n",
    "    \n",
    "    c8 = layers.Conv2D(64, 3, padding='same', use_bias=False, name=\"dec_stage8_conv1\")(c8)\n",
    "    c8 = InstanceNormalization(name=\"dec_stage8_in1\")(c8)\n",
    "    c8 = layers.Activation('swish', name=\"dec_stage8_relu1\")(c8)\n",
    "    c8 = RGCM(c8, 64, name=\"dec_stage8_rgcm\")\n",
    "    c8 = CBAM(c8, name=\"dec_stage8_cbam\")\n",
    "    \n",
    "    # Block 9\n",
    "    u9 = layers.UpSampling2D(2, interpolation='nearest', name=\"dec_stage9_up\")(c8)\n",
    "    g9 = GABM(xl=r1, xg=u9, filters=32, name=\"dec_stage9_gabm\")\n",
    "    c9 = layers.Concatenate(name=\"dec_stage9_concat\")([u9, g9])\n",
    "    \n",
    "    c9 = layers.Conv2D(32, 3, padding='same', use_bias=False, name=\"dec_stage9_conv1\")(c9)\n",
    "    c9 = InstanceNormalization(name=\"dec_stage9_in1\")(c9)\n",
    "    c9 = layers.Activation('swish', name=\"dec_stage9_relu1\")(c9)\n",
    "    c9 = RGCM(c9, 32, name=\"dec_stage9_rgcm\")\n",
    "    c9 = CBAM(c9, name=\"dec_stage9_cbam\")\n",
    "\n",
    "    edge_x = layers.Conv2D(32, 3, padding='same', activation='swish', name=\"head_edge_conv\")(c9)\n",
    "    edge_out = layers.Conv2D(1, 1, activation='sigmoid', name='edge_out', dtype='float32')(edge_x)\n",
    "\n",
    "    c9 = layers.SpatialDropout2D(0.1)(c9)\n",
    "    seg_out = layers.Conv2D(1, 1, activation='sigmoid', name='seg_out', dtype='float32')(c9)\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=[seg_out, edge_out, cls_out], name=\"ARGA_Unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:31:26.468720Z",
     "iopub.status.busy": "2026-01-09T04:31:26.468539Z",
     "iopub.status.idle": "2026-01-09T04:31:26.486535Z",
     "shell.execute_reply": "2026-01-09T04:31:26.485555Z",
     "shell.execute_reply.started": "2026-01-09T04:31:26.468691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. LOSS & METRICS & SUPPORT FUNCTION\n",
    "# ==========================================\n",
    "def dice_coef(y_true, y_pred, smooth=1e-5):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2]) + smooth)\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, alpha=0.4, beta=0.6, gamma=2.0, smooth=1.0):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    fp = tf.reduce_sum((1 - y_true) * y_pred, axis=[1, 2])\n",
    "    fn = tf.reduce_sum(y_true * (1 - y_pred), axis=[1, 2])\n",
    "    tversky_index = (tp + smooth) / (tp + alpha * fn + (1 - alpha) * fp + smooth)\n",
    "    loss = tf.pow((1 - tversky_index), gamma)\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "class WeightedEdgeLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, pos_weight=10.0, **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        loss = - (self.pos_weight * y_true * tf.math.log(y_pred) + \n",
    "                  (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "        \n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "def log_cosh_dice_loss(y_true, y_pred, smooth=1e-5):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss = 1.0 - dice\n",
    "    return tf.math.log(tf.math.cosh(dice_loss))\n",
    "\n",
    "def edge_dice_loss(y_true, y_pred, smooth=1e-5):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return 1.0 - score\n",
    "\n",
    "def boundary_consistency_loss(seg_pred, edge_pred):\n",
    "    \n",
    "    sobel_x = tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], tf.float32)\n",
    "    sobel_x = tf.reshape(sobel_x, [3, 3, 1, 1])\n",
    "    sobel_y = tf.constant([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], tf.float32)\n",
    "    sobel_y = tf.reshape(sobel_y, [3, 3, 1, 1])\n",
    "\n",
    "    grad_x = tf.nn.depthwise_conv2d(seg_pred, sobel_x, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    grad_y = tf.nn.depthwise_conv2d(seg_pred, sobel_y, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    seg_boundary = tf.sqrt(tf.square(grad_x) + tf.square(grad_y) + 1e-7)\n",
    "    \n",
    "    seg_boundary = seg_boundary / (tf.reduce_max(seg_boundary) + 1e-7)\n",
    "    \n",
    "    return tf.reduce_mean(tf.abs(seg_boundary - edge_pred))\n",
    "\n",
    "def scale_consistency_loss(model, images, pred_orig, scale_factor=0.75):\n",
    "    B, H, W, C = images.shape\n",
    "    new_h = int(TARGET_HEIGHT * scale_factor)\n",
    "    new_w = int(TARGET_WIDTH * scale_factor)\n",
    "    \n",
    "    images_scaled = tf.image.resize(images, [new_h, new_w])\n",
    "\n",
    "    pad_h = TARGET_HEIGHT - new_h\n",
    "    pad_w = TARGET_WIDTH - new_w\n",
    "    images_scaled_padded = tf.image.pad_to_bounding_box(images_scaled, 0, 0, TARGET_HEIGHT, TARGET_WIDTH)\n",
    "\n",
    "    preds_scaled_padded = model(images_scaled_padded, training=True)\n",
    "    pred_seg_scaled = preds_scaled_padded[0]\n",
    "\n",
    "    pred_orig_resized = tf.image.resize(pred_orig, [new_h, new_w])\n",
    "    pred_orig_consistent = tf.image.pad_to_bounding_box(pred_orig_resized, 0, 0, TARGET_HEIGHT, TARGET_WIDTH)\n",
    "    \n",
    "    mask_valid = tf.ones((B, new_h, new_w, 1))\n",
    "    mask_valid = tf.image.pad_to_bounding_box(mask_valid, 0, 0, TARGET_HEIGHT, TARGET_WIDTH)\n",
    "    \n",
    "    mse = tf.square(pred_seg_scaled - pred_orig_consistent)\n",
    "    consistency_loss = tf.reduce_sum(mse * mask_valid) / (tf.reduce_sum(mask_valid) + 1e-5)\n",
    "    \n",
    "    return consistency_loss\n",
    "\n",
    "def mixup_batch(inputs, alpha=0.2):\n",
    "    images, labels = inputs\n",
    "    batch_size = tf.shape(images)[0]\n",
    "\n",
    "    shift = tf.random.uniform([], minval=1, maxval=batch_size, dtype=tf.int32)\n",
    "    images_two = tf.roll(images, shift=shift, axis=0)\n",
    "    labels_two = {k: tf.roll(v, shift=shift, axis=0) for k, v in labels.items()}\n",
    "    l = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 0.3) \n",
    "    \n",
    "    do_flip = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0) > 0.5\n",
    "    l = tf.where(do_flip, 1.0 - l, l)\n",
    "\n",
    "    l_cls = tf.reshape(l, [batch_size, 1])\n",
    "\n",
    "    images_mix = l * images + (1 - l) * images_two\n",
    "    \n",
    "    new_labels = {}\n",
    "\n",
    "    if 'seg_out' in labels:\n",
    "        new_labels['seg_out'] = l * labels['seg_out'] + (1 - l) * labels_two['seg_out']\n",
    "\n",
    "    if 'edge_out' in labels:\n",
    "        edge_mask_decision = tf.cast(l > 0.5, tf.float32)\n",
    "        new_labels['edge_out'] = edge_mask_decision * labels['edge_out'] + (1 - edge_mask_decision) * labels_two['edge_out']\n",
    "\n",
    "    if 'cls_out' in labels:\n",
    "        new_labels['cls_out'] = l_cls * labels['cls_out'] + (1 - l_cls) * labels_two['cls_out']\n",
    "\n",
    "    return images_mix, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:31:26.487263Z",
     "iopub.status.busy": "2026-01-09T04:31:26.487095Z",
     "iopub.status.idle": "2026-01-09T04:31:37.980661Z",
     "shell.execute_reply": "2026-01-09T04:31:37.979557Z",
     "shell.execute_reply.started": "2026-01-09T04:31:26.487249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. PRETRAIN MODEL TRÊN TOÀN DATASET\n",
    "# ==========================================\n",
    "with strategy.scope():\n",
    "    model = build_multitask_arga_unet()\n",
    "    model.build((None, TARGET_HEIGHT, TARGET_WIDTH, 3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:31:37.981382Z",
     "iopub.status.busy": "2026-01-09T04:31:37.981220Z",
     "iopub.status.idle": "2026-01-09T04:36:25.786584Z",
     "shell.execute_reply": "2026-01-09T04:36:25.784995Z",
     "shell.execute_reply.started": "2026-01-09T04:31:37.981366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# CUSTOM TRAINING LOOP (KERAS 3 SUCKS)\n",
    "# ====================================\n",
    "\n",
    "N_TRAIN = len(X_train)\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "TPU_LOOPS_COUNT = 1 \n",
    "STEPS_PER_LOOP = STEPS_PER_EPOCH\n",
    "\n",
    "class CustomScheduler:\n",
    "    def __init__(self, model, optimizer, mode='min', patience_lr=5, patience_stop=15, \n",
    "                 factor=0.5, min_lr=1e-8, save_name=\"best_model.weights.h5\"):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.mode = mode\n",
    "        self.patience_lr = patience_lr\n",
    "        self.patience_stop = patience_stop\n",
    "        self.factor = factor\n",
    "        self.min_lr = min_lr\n",
    "        self.save_name = save_name\n",
    "        \n",
    "        self.lr_wait = 0\n",
    "        self.stop_wait = 0\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.best_value = float('inf')\n",
    "            self.monitor_op = np.less\n",
    "        else:\n",
    "            self.best_value = -float('inf')\n",
    "            self.monitor_op = np.greater\n",
    "            \n",
    "    def load_best_weights(self):\n",
    "        print(f\"   Restoring best weights from {self.save_name}...\")\n",
    "        try:\n",
    "            self.model.load_weights(self.save_name)\n",
    "            print(\"   Restore successful.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Restore failed: {e}\")\n",
    "            \n",
    "    def step(self, current_value):\n",
    "        if self.monitor_op(current_value, self.best_value):\n",
    "            print(f\"   Improved ({self.best_value:.4f} -> {current_value:.4f}). Saving weights...\")\n",
    "            self.best_value = current_value\n",
    "            self.model.save_weights(self.save_name)\n",
    "            \n",
    "            self.lr_wait = 0\n",
    "            self.stop_wait = 0\n",
    "        else:\n",
    "            self.lr_wait += 1\n",
    "            self.stop_wait += 1\n",
    "            print(f\"   No improv. LR Wait: {self.lr_wait}/{self.patience_lr} | Stop Wait: {self.stop_wait}/{self.patience_stop}\")\n",
    "\n",
    "            if self.lr_wait >= self.patience_lr:\n",
    "                old_lr = float(self.optimizer.learning_rate.numpy())\n",
    "                new_lr = old_lr * self.factor\n",
    "                \n",
    "                if new_lr > self.min_lr:\n",
    "                    self.optimizer.learning_rate.assign(new_lr)\n",
    "                    print(f\"   Reduced LR to {new_lr:.1e}\")\n",
    "                    self.lr_wait = 0\n",
    "                else:\n",
    "                    print(f\"   LR reached min ({self.min_lr}). Cannot reduce further.\")\n",
    "\n",
    "            if self.stop_wait >= self.patience_stop:\n",
    "                print(\"   Early Stopping triggered.\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "def run_tpu_training(model, \n",
    "                     train_ds, \n",
    "                     val_ds, \n",
    "                     save_name='pretrain.weights.h5',\n",
    "                     mode='min',\n",
    "                     patience_lr=5,\n",
    "                     patience_st=15,\n",
    "                     value='dice',\n",
    "                     epochs=50, \n",
    "                     lr=LEARNING_RATE, \n",
    "                     weight_loss=[1.0, 0.5, 0.1],\n",
    "                     steps_per_loop=STEPS_PER_LOOP,\n",
    "                     loops_count=TPU_LOOPS_COUNT):\n",
    "    \n",
    "    with strategy.scope():\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=lr)\n",
    "        val_dice = tf.keras.metrics.Mean(name='val_dice')\n",
    "        val_cls_loss = tf.keras.metrics.Mean(name='val_cls_loss')\n",
    "        aug_layer = MedicalPreprocessingLayer(TARGET_HEIGHT, TARGET_WIDTH)\n",
    "        \n",
    "        @tf.function(jit_compile=True)\n",
    "        def train_step(inputs):\n",
    "            images, labels = aug_layer(inputs, training=True)\n",
    "            images, targets = mixup_batch((images, labels), alpha=0.2)\n",
    "            with tf.GradientTape() as tape:\n",
    "                preds = model(images, training=True)\n",
    "                \n",
    "                pred_seg = preds[0]\n",
    "                pred_edge = preds[1]\n",
    "                pred_cls = preds[2]\n",
    "                \n",
    "                if weight_loss[0] > 0:\n",
    "                    target_seg = tf.cast(targets['seg_out'], tf.float32)\n",
    "                    l_tversky = focal_tversky_loss(target_seg, pred_seg)\n",
    "                    l_logcosh = log_cosh_dice_loss(target_seg, pred_seg)\n",
    "                    l_seg = (l_tversky +  l_logcosh) * weight_loss[0]\n",
    "                else:\n",
    "                    l_seg = 0.0\n",
    "\n",
    "                if weight_loss[1] > 0:\n",
    "                    target_edge = tf.cast(targets['edge_out'], tf.float32)\n",
    "                    l_bce = WeightedEdgeLoss()(target_edge, pred_edge)\n",
    "                    l_dice = edge_dice_loss(target_edge, pred_edge)\n",
    "                    l_edge = (l_bce + l_dice) * weight_loss[1]\n",
    "                else:\n",
    "                    l_edge = 0.0\n",
    "\n",
    "                if weight_loss[2] > 0:\n",
    "                    target_cls = tf.cast(targets['cls_out'], tf.float32)\n",
    "                    l_cls_raw = tf.keras.losses.binary_crossentropy(target_cls, pred_cls, from_logits=False)\n",
    "                    l_cls = tf.reduce_mean(l_cls_raw) * weight_loss[2]\n",
    "                else:\n",
    "                    l_cls = 0.0\n",
    "                \n",
    "                l_consist = 0.0\n",
    "                l_consist_scale = 0.0\n",
    "                \n",
    "                if (weight_loss[0] > 0) or (weight_loss[1] > 0):\n",
    "                    \n",
    "                    l_consist = boundary_consistency_loss(pred_seg, pred_edge) * 0.1\n",
    "                    \n",
    "                    rand_val = tf.random.uniform([], 0, 1)\n",
    "\n",
    "                    def compute_scale():\n",
    "                        return scale_consistency_loss(model, images, pred_seg)\n",
    "                        \n",
    "                    l_scale = tf.cond(\n",
    "                        rand_val < 0.3, \n",
    "                        compute_scale, \n",
    "                        lambda: 0.0\n",
    "                    )\n",
    "                    l_consist_scale *= 0.1\n",
    "                                \n",
    "                loss = l_seg + l_edge + l_cls + l_consist + l_consist_scale\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            return loss     \n",
    "\n",
    "        @tf.function\n",
    "        def train_loop_body(iterator, steps):\n",
    "            total_loss = 0.0\n",
    "            for _ in tf.range(steps):\n",
    "                inputs = next(iterator)\n",
    "                loss = strategy.run(train_step, args=(inputs,))\n",
    "                total_loss += tf.reduce_sum(strategy.reduce(tf.distribute.ReduceOp.SUM, loss, axis=None))\n",
    "                \n",
    "            return total_loss / tf.cast(steps, tf.float32)\n",
    "\n",
    "        @tf.function(jit_compile=True)\n",
    "        def val_step_fn(inputs):\n",
    "            images, targets = aug_layer(inputs, training=False)\n",
    "            preds = model(images, training=False)\n",
    "            cls_loss = tf.keras.losses.binary_crossentropy(targets['cls_out'], preds[2], from_logits=False)\n",
    "            cls_loss = tf.reduce_mean(cls_loss)\n",
    "\n",
    "            d_score = dice_coef(targets['seg_out'], preds[0])\n",
    "    \n",
    "            return cls_loss, d_score\n",
    "    \n",
    "\n",
    "    train_dataset = strategy.experimental_distribute_dataset(train_ds)\n",
    "    val_dataset = strategy.experimental_distribute_dataset(val_ds)\n",
    "\n",
    "    scheduler = CustomScheduler(\n",
    "        model=model, \n",
    "        optimizer=optimizer, \n",
    "        mode=mode,\n",
    "        patience_lr=patience_lr,\n",
    "        patience_stop=patience_st, \n",
    "        save_name=save_name\n",
    "    )\n",
    "\n",
    "    train_iter = iter(train_dataset)\n",
    "    best_dice = -1.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0.0\n",
    "        \n",
    "        pbar = tqdm(range(loops_count), desc=f\"Ep {epoch+1}\", leave=False)\n",
    "        for _ in pbar:\n",
    "            loss = train_loop_body(train_iter, tf.constant(steps_per_loop))\n",
    "            loss_sum += float(loss)\n",
    "            pbar.set_postfix({'loss': f\"{loss:.4f}\"})\n",
    "\n",
    "        val_dice.reset_state()\n",
    "        val_cls_loss.reset_state()\n",
    "        for batch in val_ds:\n",
    "            per_replica_losses, per_replica_dice = strategy.run(val_step_fn, args=(batch,))\n",
    "    \n",
    "        total_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
    "        total_dice = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_dice, axis=None)\n",
    "        \n",
    "        val_cls_loss.update_state(total_loss)\n",
    "        val_dice.update_state(total_dice)\n",
    "            \n",
    "        v_dice = float(val_dice.result())\n",
    "        v_cls = float(val_cls_loss.result())\n",
    "        curr_lr = float(optimizer.learning_rate.numpy())\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss_sum/loops_count:.4f} | Dice: {v_dice:.4f} | Cls loss: {v_cls:.4f} | LR: {curr_lr:.1e}\")\n",
    "        \n",
    "        if value=='dice':\n",
    "            if scheduler.step(v_dice):\n",
    "                break\n",
    "        else:\n",
    "            if scheduler.step(v_cls):\n",
    "                break\n",
    "\n",
    "    scheduler.load_best_weights()\n",
    "    return model\n",
    "\n",
    "print(\"Pretrain Multi-Task...\")\n",
    "model = run_tpu_training(\n",
    "    model=model,\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    value='dice',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:39:00.820358Z",
     "iopub.status.busy": "2026-01-09T04:39:00.820116Z",
     "iopub.status.idle": "2026-01-09T04:39:02.412598Z",
     "shell.execute_reply": "2026-01-09T04:39:02.411130Z",
     "shell.execute_reply.started": "2026-01-09T04:39:00.820342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for var in ['X_train', 'y_train', 'X_val', 'y_val', 'train_ds', 'val_ds', 'train_dataset', 'val_dataset']:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:39:29.023634Z",
     "iopub.status.busy": "2026-01-09T04:39:29.023363Z",
     "iopub.status.idle": "2026-01-09T04:39:36.357826Z",
     "shell.execute_reply": "2026-01-09T04:39:36.356073Z",
     "shell.execute_reply.started": "2026-01-09T04:39:29.023614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 6. TẠO DATASET ĐÍCH ĐỂ FINETUNE\n",
    "# ===============================\n",
    "def check_label(mask_path):\n",
    "    msk = cv2.imread(mask_path, 0)\n",
    "    label = 1 if np.max(msk) > 0 else 0\n",
    "    return mask_path, label\n",
    "\n",
    "def prepare_finetune_dataframe(data_dir):\n",
    "    all_mask_paths = glob.glob(os.path.join(data_dir, \"*_mask.png\"))\n",
    "    img_paths = []\n",
    "    valid_mask_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"Đang quét dữ liệu và tạo nhãn...\")\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        future_to_path = {}\n",
    "        for m_path in all_mask_paths:\n",
    "            i_path = m_path.replace('_mask.png', '.png')\n",
    "            if os.path.exists(i_path):\n",
    "                img_paths.append(i_path)\n",
    "                valid_mask_paths.append(m_path)\n",
    "                future_to_path[executor.submit(check_label, m_path)] = m_path\n",
    "        \n",
    "        path_to_label = {}\n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_path), total=len(valid_mask_paths)):\n",
    "            _, label = future.result()\n",
    "            path_to_label[future_to_path[future]] = label\n",
    "            \n",
    "    final_labels = [path_to_label[p] for p in valid_mask_paths]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'image_path': img_paths,\n",
    "        'mask_path': valid_mask_paths,\n",
    "        'has_nerve': final_labels\n",
    "    })\n",
    "    \n",
    "    df['patient_id'] = df['image_path'].apply(lambda x: os.path.basename(x).split('_')[0])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def merge_and_remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Gộp mask của các ảnh trùng nhau bằng phép tính MAX (Union).\n",
    "    \"\"\"\n",
    "    print(f\"Original size: {len(df)}\")\n",
    "    hashes = {}\n",
    "    hash_to_masks = {}\n",
    "    hash_to_img_path = {}\n",
    "    hash_to_first_idx = {}\n",
    "    print(\"Grouping duplicates...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            image = Image.open(row['image_path'])\n",
    "            h = str(imagehash.phash(image))\n",
    "            \n",
    "            if h not in hash_to_masks:\n",
    "                hash_to_masks[h] = []\n",
    "                hash_to_img_path[h] = row['image_path']\n",
    "                hash_to_first_idx[h] = idx\n",
    "                \n",
    "            hash_to_masks[h].append(row['mask_path'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "    final_data = []\n",
    "    print(\"Merging masks...\")\n",
    "    os.makedirs(\"merged_masks\", exist_ok=True)\n",
    "    \n",
    "    for h, mask_paths in tqdm(hash_to_masks.items()):\n",
    "        if len(mask_paths) == 1:\n",
    "            final_data.append({\n",
    "                'image_path': hash_to_img_path[h],\n",
    "                'mask_path': mask_paths[0],\n",
    "                'has_nerve': 1 if cv2.imread(mask_paths[0], 0).max() > 0 else 0\n",
    "            })\n",
    "        else:\n",
    "            merged_mask = None\n",
    "            for mp in mask_paths:\n",
    "                m = cv2.imread(mp, 0)\n",
    "                if merged_mask is None:\n",
    "                    merged_mask = m\n",
    "                else:\n",
    "                    merged_mask = np.maximum(merged_mask, m)\n",
    "            base_name = os.path.basename(hash_to_img_path[h]).replace('.png', '')\n",
    "            new_mask_path = f\"merged_masks/{base_name}_merged_mask.png\"\n",
    "            cv2.imwrite(new_mask_path, merged_mask)\n",
    "            \n",
    "            final_data.append({\n",
    "                'image_path': hash_to_img_path[h],\n",
    "                'mask_path': new_mask_path,\n",
    "                'has_nerve': 1 if np.max(merged_mask) > 0 else 0\n",
    "            })\n",
    "\n",
    "    new_df = pd.DataFrame(final_data)\n",
    "    new_df['patient_id'] = new_df['image_path'].apply(lambda x: os.path.basename(x).split('_')[0])\n",
    "    \n",
    "    print(f\"Final size after merging: {len(new_df)}\")\n",
    "    return new_df\n",
    "    \n",
    "def split_finetune_data(df, n_splits=5):\n",
    "    \n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    df['fold'] = -1\n",
    "    \n",
    "    X = df['image_path']\n",
    "    y = df['has_nerve']\n",
    "    groups = df['patient_id']\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(sgkf.split(X, y, groups)):\n",
    "        df.loc[val_idx, 'fold'] = fold_idx\n",
    "        \n",
    "    return df\n",
    "\n",
    "df_finetune = prepare_finetune_dataframe(PROCESSED_USNS_DIR)\n",
    "df_finetune = merge_and_remove_duplicates(df_finetune)\n",
    "df_finetune = split_finetune_data(df_finetune, n_splits=5)\n",
    "\n",
    "fold_idx = 0\n",
    "\n",
    "df_train = df_finetune[df_finetune['fold'] != fold_idx]\n",
    "\n",
    "df_val = df_finetune[df_finetune['fold'] == fold_idx]\n",
    "\n",
    "print(f\"Final Train Size: {len(df_train)}\")\n",
    "print(f\"Final Val Size  : {len(df_val)}\")\n",
    "\n",
    "train_imgs = df_train['image_path'].tolist()\n",
    "train_masks = df_train['mask_path'].tolist()\n",
    "\n",
    "val_imgs = df_val['image_path'].tolist()\n",
    "val_masks = df_val['mask_path'].tolist()\n",
    "df_train_pos = df_train[df_train['has_nerve'] == 1].copy()\n",
    "df_val_pos = df_val[df_val['has_nerve'] == 1].copy()\n",
    "\n",
    "X_train_pos, y_train_pos = load_dataset_into_ram(df_train_pos['image_path'].tolist(), df_train_pos['mask_path'].tolist())\n",
    "X_val_pos, y_val_pos = load_dataset_into_ram(df_val_pos['image_path'].tolist(), df_val_pos['mask_path'].tolist())\n",
    "X_train, y_train = load_dataset_into_ram(train_imgs, train_masks)\n",
    "X_val, y_val = load_dataset_into_ram(val_imgs, val_masks)\n",
    "\n",
    "train_ds_pos = get_unified_dataset(X_train_pos, y_train_pos, training=True)\n",
    "val_ds_pos = get_unified_dataset(X_val_pos, y_val_pos, training=False)\n",
    "\n",
    "train_ds = get_unified_dataset(X_train, y_train, training=True)\n",
    "val_ds = get_unified_dataset(X_val, y_val, training=False)\n",
    "\n",
    "STEPS_PER_EPOCH = len(X_train) // (BATCH_SIZE // 2)\n",
    "\n",
    "SETPS_PER_EPOCH_POS = len(X_train_pos) // (BATCH_SIZE // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:39:41.590081Z",
     "iopub.status.busy": "2026-01-09T04:39:41.589813Z",
     "iopub.status.idle": "2026-01-09T05:01:47.684307Z",
     "shell.execute_reply": "2026-01-09T05:01:47.682643Z",
     "shell.execute_reply.started": "2026-01-09T04:39:41.590063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 7. FINETUNE TRÊN DATASET ĐÍCH\n",
    "# ==============================\n",
    "print(\"Training Seg Branch ...\")\n",
    "with strategy.scope():\n",
    "    model = build_multitask_arga_unet()\n",
    "\n",
    "    model.load_weights('/kaggle/working/pretrain.weights.h5', skip_mismatch=True)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if layer.name.startswith('dec_'):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "model = run_tpu_training(\n",
    "    model=model,\n",
    "    train_ds=train_ds_pos,\n",
    "    val_ds=val_ds_pos,\n",
    "    mode='max',\n",
    "    patience_lr=5,\n",
    "    patience_st=12,\n",
    "    value='dice',\n",
    "    epochs=8,\n",
    "    weight_loss=[1.0, 0.5, 0.0],\n",
    "    lr=1e-3,\n",
    "    save_name=\"stage1_best.weights.h5\",\n",
    "    steps_per_loop=SETPS_PER_EPOCH_POS\n",
    ")\n",
    "with strategy.scope():\n",
    "    for layer in model.layers:\n",
    "        if layer.name.startswith('head_cls_'):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "\n",
    "model = run_tpu_training(\n",
    "    model=model,\n",
    "    train_ds=train_ds_pos,\n",
    "    val_ds=val_ds_pos,\n",
    "    mode='max',\n",
    "    patience_lr=5,\n",
    "    patience_st=12,\n",
    "    value='dice',\n",
    "    epochs=20,\n",
    "    weight_loss=[4.0, 2.0, 0.0],\n",
    "    lr=3.2e-4,\n",
    "    save_name=\"stage1_best.weights.h5\",\n",
    "    steps_per_loop=SETPS_PER_EPOCH_POS\n",
    ")\n",
    "\n",
    "print(\"Training CLS branch...\")\n",
    "with strategy.scope():\n",
    "    for layer in model.layers:\n",
    "        if layer.name.startswith('head_cls_'):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "model = run_tpu_training(\n",
    "    model=model,\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    mode='min',\n",
    "    patience_lr=3,\n",
    "    patience_st=15,\n",
    "    value='cls',\n",
    "    epochs=20,\n",
    "    weight_loss=[0.0, 0.0, 1.0],\n",
    "    lr=8e-5,\n",
    "    save_name=\"stage2_best.weights.h5\",\n",
    "    steps_per_loop=STEPS_PER_EPOCH\n",
    ")\n",
    "\n",
    "print(\"Finetune sync...\")\n",
    "with strategy.scope():\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "model = run_tpu_training(\n",
    "    model=model,\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    mode='max',\n",
    "    patience_lr=5,\n",
    "    patience_st=15,\n",
    "    value='dice',\n",
    "    epochs=30,\n",
    "    weight_loss=[0.5, 0.5, 1.5],\n",
    "    lr=8e-5,\n",
    "    save_name=\"finetune_best.weights.h5\",\n",
    "    steps_per_loop=STEPS_PER_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2026-01-09T05:04:03.546Z",
     "iopub.execute_input": "2026-01-09T05:02:05.502527Z",
     "iopub.status.busy": "2026-01-09T05:02:05.502210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# 8. THRESHOLD CHECKING TRÊN TẬP ĐÍCH MÔ PHỎNG\n",
    "# =============================================\n",
    "MC_SAMPLES = 16\n",
    "with strategy.scope(): \n",
    "    model = build_multitask_arga_unet()\n",
    "    model.load_weights('/kaggle/working/finetune_best.weights.h5', skip_mismatch=True)\n",
    "    aug_layer = MedicalPreprocessingLayer(TARGET_HEIGHT, TARGET_WIDTH)\n",
    "\n",
    "def val_adapter(img, mask):\n",
    "    rank = tf.rank(mask)\n",
    "    reduction_axes = tf.range(1, rank) \n",
    "    has_object = tf.reduce_max(tf.cast(mask, tf.float32), axis=reduction_axes) > 0.0\n",
    "    label_cls = tf.cast(has_object, tf.float32)\n",
    "    label_cls = tf.reshape(label_cls, [-1, 1]) \n",
    "    return img, {'seg_out': mask, 'cls_out': label_cls}\n",
    "\n",
    "val_dataset_inference = val_ds.map(val_adapter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "@tf.function\n",
    "def predict_step(inputs):\n",
    "    current_batch_size = tf.shape(inputs)[0] \n",
    "    preprocessed = aug_layer(inputs, training=False)\n",
    "\n",
    "    if isinstance(preprocessed, (list, tuple)):\n",
    "        img_normalized = preprocessed[0]\n",
    "    else:\n",
    "        img_normalized = preprocessed\n",
    "\n",
    "    img_orig = img_normalized\n",
    "    img_flip = tf.image.flip_left_right(img_normalized)\n",
    "    combined_tta = tf.concat([img_orig, img_flip], axis=0)\n",
    "    batch_ready = tf.repeat(combined_tta, MC_SAMPLES, axis=0)\n",
    "    \n",
    "    outputs = model(batch_ready, training=True)\n",
    "    \n",
    "    seg_preds_all = outputs[0]\n",
    "    cls_preds_all = outputs[-1]\n",
    "\n",
    "    if tf.shape(cls_preds_all)[-1] > 1:\n",
    "        cls_preds_all = cls_preds_all[..., 0:1]\n",
    "\n",
    "    seg_reshaped = tf.reshape(seg_preds_all, [2 * current_batch_size, MC_SAMPLES, TARGET_HEIGHT, TARGET_WIDTH, 1])\n",
    "    cls_reshaped = tf.reshape(cls_preds_all, [2 * current_batch_size, MC_SAMPLES, 1])\n",
    "\n",
    "    seg_mean_mc = tf.reduce_mean(seg_reshaped, axis=1)\n",
    "    seg_var_mc  = tf.math.reduce_variance(seg_reshaped, axis=1)\n",
    "    cls_mean_mc = tf.reduce_mean(cls_reshaped, axis=1)\n",
    "\n",
    "    seg_mean_orig, seg_mean_flip = tf.split(seg_mean_mc, num_or_size_splits=2, axis=0)\n",
    "    seg_var_orig,  seg_var_flip  = tf.split(seg_var_mc,  num_or_size_splits=2, axis=0) \n",
    "    cls_mean_orig, cls_mean_flip = tf.split(cls_mean_mc, num_or_size_splits=2, axis=0)\n",
    "\n",
    "    seg_mean_flip_back = tf.image.flip_left_right(seg_mean_flip)\n",
    "    seg_var_flip_back  = tf.image.flip_left_right(seg_var_flip) \n",
    "\n",
    "    final_seg = (seg_mean_orig + seg_mean_flip_back) / 2.0\n",
    "    final_unc = (seg_var_orig + seg_var_flip_back) / 2.0\n",
    "    final_cls = (cls_mean_orig + cls_mean_flip) / 2.0\n",
    "    \n",
    "    return final_seg, final_cls, final_unc\n",
    "    \n",
    "def tune_all_parameters(strategy, val_ds, predict_step_fn, target_pos_ratio=0.2):\n",
    "    print(\"--- Hyper-parameter tunning processing ---\")\n",
    "    \n",
    "    cache_pred_cls = []\n",
    "    cache_pred_seg = []\n",
    "    cache_pred_unc = [] \n",
    "    cache_true_cls = []\n",
    "    cache_true_seg = []\n",
    "    \n",
    "    dist_val = strategy.experimental_distribute_dataset(val_ds)\n",
    "    \n",
    "    print(\"1. Đang chạy Inference trên toàn bộ tập Validation...\")\n",
    "    \n",
    "    for batch_inputs, batch_labels in tqdm(dist_val):\n",
    "        if isinstance(batch_labels, dict):\n",
    "            lbl_cls = strategy.gather(batch_labels['cls_out'], axis=0).numpy()\n",
    "            lbl_seg = strategy.gather(batch_labels['seg_out'], axis=0).numpy()\n",
    "        else:\n",
    "            print(\"Error: Dataset format not dict! Kiểm tra lại pipeline.\")\n",
    "            break\n",
    "\n",
    "        preds = strategy.run(predict_step_fn, args=(batch_inputs,))\n",
    "        \n",
    "        pred_seg = strategy.gather(preds[0], axis=0).numpy()\n",
    "        pred_cls = strategy.gather(preds[1], axis=0).numpy()\n",
    "            \n",
    "        pred_unc = strategy.gather(preds[2], axis=0).numpy()\n",
    "        \n",
    "        cache_pred_cls.append(pred_cls)\n",
    "        cache_pred_seg.append(pred_seg)\n",
    "        cache_pred_unc.append(pred_unc)\n",
    "        cache_true_cls.append(lbl_cls)\n",
    "        cache_true_seg.append(lbl_seg)\n",
    "\n",
    "    all_pred_cls = np.concatenate(cache_pred_cls).flatten()\n",
    "    all_true_cls = np.concatenate(cache_true_cls).flatten()\n",
    "    all_pred_seg = np.concatenate(cache_pred_seg)\n",
    "    all_pred_unc = np.concatenate(cache_pred_unc)\n",
    "    all_true_seg = np.concatenate(cache_true_seg)\n",
    "\n",
    "    if np.max(all_true_seg) > 1:\n",
    "        all_true_seg = all_true_seg / 255.0\n",
    "    print(f\"-> Total: {len(all_pred_cls)} samples.\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(all_true_cls, all_pred_cls)\n",
    "    f1_scores = 2 * recall * precision / (recall + precision + 1e-7)\n",
    "    \n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_cls_thresh = thresholds[best_idx]\n",
    "    best_f1 = f1_scores[best_idx]\n",
    "    \n",
    "    print(f\"-> Best CLS Threshold: {best_cls_thresh:.4f} (Max F1: {best_f1:.4f})\")\n",
    "    \n",
    "    print(\"-> Applying Soft Gating & Uncertainty Penalty...\")\n",
    "    \n",
    "    pos_idx = np.where(all_true_cls == 1)[0]\n",
    "    \n",
    "    if len(pos_idx) == 0:\n",
    "        best_final_thresh = 0.5\n",
    "    else:\n",
    "        sub_pred_seg = all_pred_seg[pos_idx]\n",
    "        sub_pred_cls = all_pred_cls[pos_idx].reshape(-1, 1, 1, 1)\n",
    "        sub_pred_unc = all_pred_unc[pos_idx]\n",
    "        sub_true_seg = all_true_seg[pos_idx]\n",
    "        \n",
    "        penalty_weight = 0.6\n",
    "        soft_mask = (sub_pred_seg - penalty_weight * sub_pred_unc) * sub_pred_cls\n",
    "        \n",
    "        soft_mask = np.clip(soft_mask, 0.0, 1.0)\n",
    "    \n",
    "        best_dice = 0.0\n",
    "        best_final_thresh = 0.5\n",
    "        \n",
    "        for t in np.arange(0.1, 0.9, 0.05):\n",
    "            pred_bin = (soft_mask > t).astype(np.float32)\n",
    "            \n",
    "            intersection = np.sum(sub_true_seg * pred_bin, axis=(1, 2, 3))\n",
    "            union = np.sum(sub_true_seg, axis=(1, 2, 3)) + np.sum(pred_bin, axis=(1, 2, 3))\n",
    "            dices = (2. * intersection + 1e-5) / (union + 1e-5)\n",
    "            mean_dice = np.mean(dices)\n",
    "            \n",
    "            if mean_dice > best_dice:\n",
    "                best_dice = mean_dice\n",
    "                best_final_thresh = t\n",
    "                \n",
    "        print(f\"-> Best COMBINED Threshold: {best_final_thresh:.4f} (Dice: {best_dice:.4f})\")\n",
    "\n",
    "    print(\"Tune UNCERTAINTY Threshold...\")\n",
    "    tp_uncs = []\n",
    "    fp_uncs = []\n",
    "    \n",
    "    print(\"   Analyzing connected components...\")\n",
    "    for i in tqdm(range(len(all_pred_seg))):\n",
    "        pred_mask_raw = all_pred_seg[i, ..., 0]\n",
    "        unc_map_raw = all_pred_unc[i, ..., 0]\n",
    "        true_mask_raw = all_true_seg[i, ..., 0]\n",
    "        \n",
    "        pred_mask_bin = (pred_mask_raw > best_final_thresh).astype(np.uint8)\n",
    "        true_mask_bin = true_mask_raw.astype(np.uint8)\n",
    "        \n",
    "        num, labels_im = cv2.connectedComponents(pred_mask_bin)\n",
    "        \n",
    "        for region_idx in range(1, num):\n",
    "            region_mask = (labels_im == region_idx).astype(np.uint8)\n",
    "            mean_u = np.mean(unc_map_raw[region_mask == 1])\n",
    "            \n",
    "            intersection = np.sum(region_mask * true_mask_bin)\n",
    "            \n",
    "            if intersection > 0:\n",
    "                tp_uncs.append(mean_u)\n",
    "            else:\n",
    "                fp_uncs.append(mean_u)\n",
    "                \n",
    "    print(f\"   Collected TP regions: {len(tp_uncs)}\")\n",
    "    print(f\"   Collected FP regions: {len(fp_uncs)}\")\n",
    "    \n",
    "    median_tp = np.median(tp_uncs) if len(tp_uncs) > 0 else 0\n",
    "    median_fp = np.median(fp_uncs) if len(fp_uncs) > 0 else 1.0\n",
    "    \n",
    "    suggested_unc_thresh = (median_tp + median_fp) / 2\n",
    "    print(f\"-> Best UNCERTAINTY Threshold: {suggested_unc_thresh:.4f}\")\n",
    "    \n",
    "    return best_cls_thresh, best_final_thresh, suggested_unc_thresh\n",
    "\n",
    "BEST_CLS, BEST_SEG, BEST_UNC = tune_all_parameters(\n",
    "    strategy, \n",
    "    val_dataset_inference,\n",
    "    predict_step, \n",
    "    target_pos_ratio=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 9.THỰC HIỆN PREDICT\n",
    "# ====================\n",
    "TEST_DIR = '/kaggle/input/ultrasound-nerve-segmentation/test'\n",
    "TEST_PNG_DIR = '/kaggle/working/test_usns_png'\n",
    "BATCH_SIZE_PREDICT = 4 * strategy.num_replicas_in_sync\n",
    "\n",
    "if not os.path.exists(TEST_PNG_DIR):\n",
    "    os.makedirs(TEST_PNG_DIR)\n",
    "test_files_tif = glob.glob(os.path.join(TEST_DIR, \"*.tif\"))\n",
    "print(f\"Converting {len(test_files_tif)} test images to PNG...\")\n",
    "    \n",
    "for t_path in tqdm(test_files_tif):\n",
    "    base_name = os.path.basename(t_path).replace('.tif', '.png')\n",
    "    img = cv2.imread(t_path)\n",
    "    if img is not None:\n",
    "        cv2.imwrite(os.path.join(TEST_PNG_DIR, base_name), img)\n",
    "\n",
    "print(\"Test conversion complete.\")\n",
    "\n",
    "test_png_files = glob.glob(os.path.join(TEST_PNG_DIR, \"*.png\"))\n",
    "test_png_files.sort() \n",
    "\n",
    "N_ORIGINAL = len(test_png_files)\n",
    "remainder = N_ORIGINAL % BATCH_SIZE_PREDICT\n",
    "if remainder != 0:\n",
    "    pad_len = BATCH_SIZE_PREDICT - remainder\n",
    "    test_png_files += test_png_files[:pad_len]\n",
    "    print(f\"Padding dataset: {N_ORIGINAL} -> {len(test_png_files)} images (Added {pad_len})\")\n",
    "else:\n",
    "    print(\"No padding needed.\")\n",
    "\n",
    "def read_test_image(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.image.resize(img, [TARGET_HEIGHT, TARGET_WIDTH])\n",
    "    img.set_shape([TARGET_HEIGHT, TARGET_WIDTH, 3])\n",
    "    return img\n",
    "\n",
    "def get_test_dataset(image_paths):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    dataset = dataset.map(read_test_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE_PREDICT, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "test_dataset = get_test_dataset(test_png_files)\n",
    "dist_test_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
    "\n",
    "def filter_by_uncertainty(pred_mask, unc_map, threshold=0.5):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(pred_mask.astype(np.uint8))\n",
    "    \n",
    "    final_mask = np.zeros_like(pred_mask)\n",
    "    \n",
    "    for i in range(1, num_labels):\n",
    "        component_mask = (labels == i)\n",
    "        mean_unc = np.mean(unc_map[component_mask])\n",
    "        if mean_unc < threshold:\n",
    "            final_mask[component_mask] = 1\n",
    "            \n",
    "    return final_mask\n",
    "\n",
    "print(\"Start predicting...\")\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "    \n",
    "def remove_small_objects(mask, min_size=100):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    cleaned_mask = np.zeros_like(mask)\n",
    "    for i in range(1, num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area >= min_size:\n",
    "            cleaned_mask[labels == i] = 1\n",
    "    return cleaned_mask\n",
    "    \n",
    "def keep_largest_component(mask):\n",
    "    mask = mask.astype(np.uint8)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    if num_labels < 2:\n",
    "        return mask\n",
    "    largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "    cleaned_mask = np.zeros_like(mask)\n",
    "    cleaned_mask[labels == largest_label] = 1\n",
    "    return cleaned_mask\n",
    "\n",
    "def fill_holes(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filled_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(filled_mask, contours, -1, 1, thickness=cv2.FILLED)\n",
    "    return filled_mask\n",
    "\n",
    "data = []\n",
    "file_idx = 0\n",
    "total_batches = len(test_png_files) // BATCH_SIZE_PREDICT + 1\n",
    "\n",
    "all_masks = []\n",
    "all_labels = []\n",
    "all_uncs = []\n",
    "\n",
    "for batch_images in tqdm(dist_test_dataset, total=total_batches):\n",
    "    batch_outputs = strategy.run(predict_step, args=(batch_images,))\n",
    "    \n",
    "    masks_tensor = strategy.gather(batch_outputs[0], axis=0)\n",
    "    labels_tensor = strategy.gather(batch_outputs[1], axis=0)\n",
    "    uncs_tensor   = strategy.gather(batch_outputs[2], axis=0)\n",
    "\n",
    "    all_masks.append(masks_tensor.numpy())\n",
    "    all_labels.append(labels_tensor.numpy())\n",
    "    all_uncs.append(uncs_tensor.numpy())\n",
    "    \n",
    "final_masks = np.concatenate(all_masks, axis=0)\n",
    "final_labels = np.concatenate(all_labels, axis=0)\n",
    "final_uncs = np.concatenate(all_uncs, axis=0)\n",
    "\n",
    "final_masks = final_masks[:N_ORIGINAL]\n",
    "final_labels = final_labels[:N_ORIGINAL]\n",
    "final_uncs = final_uncs[:N_ORIGINAL]\n",
    "\n",
    "original_files = test_png_files[:N_ORIGINAL]\n",
    "\n",
    "for i, file_path in enumerate(tqdm(original_files)):\n",
    "    img_id = int(os.path.splitext(os.path.basename(file_path))[0])\n",
    "\n",
    "    mask_prob = final_masks[i, :, :, 0]\n",
    "    nerve_prob = final_labels[i, 0]\n",
    "    unc_map_prob = final_uncs[i, :, :, 0]\n",
    "\n",
    "    mask_prob_resized = cv2.resize(mask_prob, (580, 420), interpolation=cv2.INTER_LINEAR)\n",
    "    unc_map_resized = cv2.resize(unc_map_prob, (580, 420), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    mask_prob_penalized = mask_prob_resized - 0.5 * unc_map_resized\n",
    "    final_prob_map = mask_prob_penalized * nerve_prob\n",
    "        \n",
    "    mask_binary = (final_prob_map > BEST_SEG).astype(np.uint8)\n",
    "\n",
    "    mask_filtered = filter_by_uncertainty(mask_binary, unc_map_resized, threshold=BEST_UNC)\n",
    "\n",
    "    mask_clean = remove_small_objects(mask_filtered, min_size=100)\n",
    "    mask_clean = fill_holes(mask_clean)\n",
    "    mask_clean = keep_largest_component(mask_clean)\n",
    "        \n",
    "    mask_area = np.sum(mask_clean)\n",
    "    if mask_area < 100:\n",
    "        mask_clean = np.zeros_like(mask_clean)\n",
    "            \n",
    "    if np.sum(mask_clean) == 0:\n",
    "        encoded = \"\"\n",
    "    else:\n",
    "        encoded = rle_encode(mask_clean)\n",
    "            \n",
    "    data.append({\n",
    "        \"img\": img_id,\n",
    "        \"pixels\": encoded\n",
    "    })\n",
    "# Lưu Submission\n",
    "data = sorted(data, key=lambda x: x['img'])\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "databundleVersionId": 862050,
     "isSourceIdPinned": false,
     "sourceId": 5144,
     "sourceType": "competition"
    },
    {
     "datasetId": 1209633,
     "sourceId": 2021025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1498729,
     "sourceId": 2476474,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6761041,
     "sourceId": 10881089,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7974826,
     "sourceId": 12622088,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31194,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
